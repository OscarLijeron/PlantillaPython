# -*- coding: utf-8 -*-
"""
Autor: Xabier Gabi√±a y Ibai Sologestoa.
Script para la implementaci√≥n del algoritmo de clasificaci√≥n
"""

import random
import sys
import signal
import argparse
import pandas as pd
import numpy as np
import string
import pickle
import time
import json
import csv
import os
import unicodedata
import re
import joblib
from colorama import Fore
# Sklearn
from sklearn.naive_bayes import MultinomialNB
from sklearn.calibration import LabelEncoder
from sklearn.metrics import f1_score, confusion_matrix, classification_report,recall_score, roc_auc_score,accuracy_score, precision_score
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler, Normalizer, StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
# Nltk
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
# Imblearn
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler,SMOTE,ADASYN
from tqdm import tqdm

# Funciones auxiliares

def signal_handler(sig, frame):
    """
    Funci√≥n para manejar la se√±al SIGINT (Ctrl+C)
    :param sig: Se√±al
    :param frame: Frame
    """
    print("\nSaliendo del programa...")
    sys.exit(0)

def parse_args():
    """
    Funci√≥n para parsear los argumentos de entrada
    """
    parse = argparse.ArgumentParser(description="Practica de algoritmos de clasificaci√≥n de datos.")
    parse.add_argument("-m", "--mode", help="Modo de ejecuci√≥n (train o test)", required=True)
    parse.add_argument("-f", "--file", help="Fichero csv (/Path_to_file)", required=True)
    parse.add_argument("-a", "--algorithm", help="Algoritmo a ejecutar (kNN, decision_tree o random_forest)", required=True)
    parse.add_argument("-p", "--prediction", help="Columna a predecir (Nombre de la columna)", required=True)
    parse.add_argument("-e", "--estimator", help="Estimador a utilizar para elegir el mejor modelo https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter", required=False, default=None)
    parse.add_argument("-c", "--cpu", help="N√∫mero de CPUs a utilizar [-1 para usar todos]", required=False, default=-1, type=int)
    parse.add_argument("-v", "--verbose", help="Muestra las metricas por la terminal", required=False, default=False, action="store_true")
    parse.add_argument("--debug", help="Modo debug [Muestra informacion extra del preprocesado y almacena el resultado del mismo en un .csv]", required=False, default=False, action="store_true")
    # Parseamos los argumentos
    args = parse.parse_args()
    
    # Leemos los parametros del JSON
    with open('config.json') as json_file:
        config = json.load(json_file)
    
    # Juntamos todo en una variable
    for key, value in config.items():
        setattr(args, key, value)
    
    # Parseamos los argumentos
    return args
    
def load_data(file):
    """
    Funci√≥n para cargar los datos de un fichero csv
    :param file: Fichero csv
    :return: Datos del fichero
    """
    try:
        data = pd.read_csv(file, encoding="latin1")
        #data = pd.read_csv(file, encoding='utf-8')
        print(Fore.GREEN+"Datos cargados con √©xito"+Fore.RESET)
        return data
    except Exception as e:
        print(Fore.RED+"Error al cargar los datos"+Fore.RESET)
        print(e)
        sys.exit(1)
'''def load_data1(file):
    """
    Funci√≥n para cargar los datos de un fichero csv
    :param file: Fichero csv
    :return: Datos del fichero
    """
    try:
        data = pd.read_csv(file, encoding="latin1",on_bad_lines='skip')
        #data = pd.read_csv(file, encoding='utf-8')
        print(Fore.GREEN+"Datos cargados con √©xito"+Fore.RESET)
        return data
    except Exception as e:
        print(Fore.RED+"Error al cargar los datos"+Fore.RESET)
        print(e)
        sys.exit(1)'''

# Funciones para calcular m√©tricas
def calcular_metricas_y_guardar(col_verdadero, col_predicho, dataf, archivo_salida="modeloSalida"):
    #Crea un archivo csvdonde estan los valores reales predecidos por el modelo y al final escribe las metricasque ha sacado el modelo
    # Crear carpeta output si no existe
    output = "output"
    os.makedirs(output, exist_ok=True)
    archivo_salida = os.path.join(output, archivo_salida)
    
    # Crear DataFrame con los datos proporcionados
    '''df = pd.DataFrame({
        'Verdadero': col_verdadero,
        'Predicho': col_predicho
    })'''
    df=dataf
    
    # Calcular m√©tricas
    accuracy = accuracy_score(col_verdadero, col_predicho)
    f1 = f1_score(col_verdadero, col_predicho, average='weighted')
    recall = recall_score(col_verdadero, col_predicho, average='weighted')
    precision= precision_score(col_verdadero, col_predicho, average='weighted')
    
    # Asegurarse de que roc_auc_score sea adecuado seg√∫n el tipo de problema
    if len(set(col_verdadero)) == 2:  # Solo aplica para clasificaci√≥n binaria
        roc_auc = roc_auc_score(col_verdadero, col_predicho)
    else:
        roc_auc = None  # Si es multiclase, roc_auc puede no ser aplicable o requerir otro enfoque
    
    # Crear DataFrame con resultados
    resultados = pd.DataFrame({
        'M√©trica': ['Accuracy', 'F1-Score', 'Recall','Precision', 'ROC-AUC'],
        'Valor': [accuracy, f1, recall, precision, roc_auc]
    })
    
    # Guardar datos y m√©tricas en CSV
    df.to_csv(archivo_salida, header=True, index=False)  # Guardar datos de verdad y predicciones
    with open(archivo_salida, 'a') as f:  # Agregar m√©tricas al archivo
        resultados.to_csv(f,header=True, index=False)
    
    print(f"M√©tricas y datos guardados en {archivo_salida}")

def calculate_fscore(y_test, y_pred):
    """
    Funci√≥n para calcular el F-score
    :param y_test: Valores reales
    :param y_pred: Valores predichos
    :return: F-score (micro), F-score (macro)
    """
    fscore_micro = f1_score(y_test, y_pred, average='micro')
    fscore_macro = f1_score(y_test, y_pred, average='macro')
    return fscore_micro, fscore_macro

def calculate_classification_report(y_test, y_pred):
    """
    Funci√≥n para calcular el informe de clasificaci√≥n
    :param y_test: Valores reales
    :param y_pred: Valores predichos
    :return: Informe de clasificaci√≥n
    """
    report = classification_report(y_test, y_pred, zero_division=0)
    return report

def calculate_confusion_matrix(y_test, y_pred):
    """
    Funci√≥n para calcular la matriz de confusi√≥n
    :param y_test: Valores reales
    :param y_pred: Valores predichos
    :return: Matriz de confusi√≥n
    """
    cm = confusion_matrix(y_test, y_pred)
    return cm

# Funciones para preprocesar los datos

def select_features():
    """
    Separa las caracter√≠sticas del conjunto de datos en caracter√≠sticas num√©ricas, de texto y categ√≥ricas.

    Returns:
        numerical_feature (DataFrame): DataFrame que contiene las caracter√≠sticas num√©ricas.
        text_feature (DataFrame): DataFrame que contiene las caracter√≠sticas de texto.
        categorical_feature (DataFrame): DataFrame que contiene las caracter√≠sticas categ√≥ricas.
    """
    try:
        # Numerical features
        numerical_feature = data.select_dtypes(include=['int64', 'float64']) # Columnas num√©ricas
        if args.prediction in numerical_feature.columns:
            numerical_feature = numerical_feature.drop(columns=[args.prediction])
        # Categorical features
        categorical_feature = data.select_dtypes(include='object')
        categorical_feature = categorical_feature.loc[:, categorical_feature.nunique() <= args.preproceso["unique_category_threshold"]] ###################
        
        # Text features
        text_feature = data.select_dtypes(include='object').drop(columns=categorical_feature.columns)

        print(Fore.GREEN+"Datos separados con √©xito"+Fore.RESET)
        
        if args.debug:
            print(Fore.MAGENTA+"> Columnas num√©ricas:\n"+Fore.RESET, numerical_feature.columns)
            print(Fore.MAGENTA+"> Columnas de texto:\n"+Fore.RESET, text_feature.columns)
            print(Fore.MAGENTA+"> Columnas categ√≥ricas:\n"+Fore.RESET, categorical_feature.columns)
        return numerical_feature, text_feature, categorical_feature
    except Exception as e:
        print(Fore.RED+"Error al separar los datos"+Fore.RESET)
        print(e)
        sys.exit(1)
def mostrar_resultados(gs, x_dev, y_dev):
    """
    Muestra los resultados del clasificador.

    Par√°metros:
    - gs: objeto GridSearchCV, el clasificador con la b√∫squeda de hiperpar√°metros.
    - x_dev: array-like, las caracter√≠sticas del conjunto de desarrollo.
    - y_dev: array-like, las etiquetas del conjunto de desarrollo.

    Imprime en la consola los siguientes resultados:
    - Mejores par√°metros encontrados por la b√∫squeda de hiperpar√°metros.
    - Mejor puntuaci√≥n obtenida por el clasificador.
    - F1-score micro del clasificador en el conjunto de desarrollo.
    - F1-score macro del clasificador en el conjunto de desarrollo.
    - Informe de clasificaci√≥n del clasificador en el conjunto de desarrollo.
    - Matriz de confusi√≥n del clasificador en el conjunto de desarrollo.
    """
    if args.verbose:
        print(Fore.MAGENTA+"> Mejores parametros:\n"+Fore.RESET, gs.best_params_)
        print(Fore.MAGENTA+"> Mejor puntuacion:\n"+Fore.RESET, gs.best_score_)
        print(Fore.MAGENTA+"> F1-score micro:\n"+Fore.RESET, calculate_fscore(y_dev, gs.predict(x_dev))[0])
        print(Fore.MAGENTA+"> F1-score macro:\n"+Fore.RESET, calculate_fscore(y_dev, gs.predict(x_dev))[1])
        print(Fore.MAGENTA+"> Informe de clasificaci√≥n:\n"+Fore.RESET, calculate_classification_report(y_dev, gs.predict(x_dev)))
        print(Fore.MAGENTA+"> Matriz de confusi√≥n:\n"+Fore.RESET, calculate_confusion_matrix(y_dev, gs.predict(x_dev)))

def preproceso():
    global data
    if args.preproceso['Preprocesar?']=='si' :
        # Identificar las columnas 'Unnamed' en el DataFrame
        unnamed_cols = [col for col in data.columns if 'Unnamed' in col]
        # Renombrar las columnas 'Unnamed' de forma que tengan nombres m√°s significativos
        new_names = {col: f"New_Column_{i}" for i, col in enumerate(unnamed_cols)}
        # Renombrar las columnas
        data.rename(columns=new_names, inplace=True)
         # Separamos los datos por tipos
        numerical_feature, text_feature, categorical_feature = select_features()

        # Concatenar con un delimitador
        if args.preproceso['cols_concatenar'][0]!="no":
            data=concatenar_columnas(data,args.preproceso['cols_concatenar'])

        if args.preproceso['missing_values'] == 'imputar':
            print("Imputaci√≥n en proceso.")
            # Configurar la estrategia de imputaci√≥n
            if args.preproceso['impute_strategy'] == 'mean':
                    imputer = SimpleImputer(strategy="mean")
                    print("Metodo es mean")
            elif args.preproceso['impute_strategy'] == 'mode':
                    imputer = SimpleImputer(strategy="most_frequent")
                    print("Metodo es moda")
            elif args.preproceso['impute_strategy'] == 'median':
                    imputer = SimpleImputer(strategy="median")
                    print("Metodo es mediana")
        

            # Obtener las columnas a imputar desde el JSON
            cols_imputar = numerical_feature
    
            # Verificar si las columnas a imputar existen en df
            cols_imputar_validas = [col for col in cols_imputar if col in data.columns]
            print(cols_imputar_validas)
            print("Valores NaN en las columnas a imputar:", data[cols_imputar_validas].isnull().sum())
            if cols_imputar_validas:  # Solo imputar si hay columnas v√°lidas
                data[cols_imputar_validas] = imputer.fit_transform(data[cols_imputar_validas])
                print("Imputaci√≥n completada.")
            else:
                print(f"‚ö†Ô∏è Advertencia: No se encontraron las columnas {cols_imputar} en X_train. Verifica los nombres.")
        elif args.preproceso['missing_values'] == 'drop':
            #cols_imputar = numerical_feature
            # Para cubrir varios casos raros:
            
            cols_imputar = args.preproceso['cols_imputar']


            print(f"üóë Eliminando filas con valores faltantes en las columnas: {cols_imputar}")
            print(cols_imputar)
            print(type(cols_imputar))

            data.dropna(subset=cols_imputar, inplace=True)    
        print("Valores faltantes en data:", data.isnull().sum())

        if args.preproceso['cols_outliers'][0]!="no":
            for colum in args.preproceso['cols_outliers']:
                remove_outliers_iqr(colum)
        
        # Pasar de categorial a n√∫merico
        if args.preproceso['cat_num?']=='si':
            if args.preproceso['categorial_features'][0]!='no' :
                cols_cat_num=args.preproceso['categorial_features']
            else:
                cols_cat_num= categorical_feature
            cat_numerico(data,cols_cat_num)
            for col in categorical_feature:
                print(f"Valores √∫nicos en {col}: {data[col].unique()}")

        if args.preproceso['normalize?']=='si':
            cols_simplificar=text_feature
            for col in cols_simplificar:
                data[col] = data[col].fillna('').apply(lambda x: limpiar_texto(x))
        print(data.head())  # Esto imprimir√° las primeras 5 filas de todas las columnas por defecto
        
        process_text(text_feature)
        
        if args.preproceso['scaling']=='standar':
            # Escalamos los datos de forma standard
            data=escaladoEstandar(data)
        elif args.preproceso['scaling']=='absmaxmin':
            # Escalamos los datos de forma absminmax
            data=maximum_absolute_scaling(data)
        elif args.preproceso['scaling']=='minmax':
            # Escalamos los datos de forma minmax
            cols=data.columns
            for col in cols :
                min_max_scaling(col)
        elif args.preproceso['scaling']=='zscore' :
            # Escalamos los datos de forma zscore
            cols=data.columns
            for col in cols :
                z_score(col)
        #eliminamos cols
        if args.preproceso['cols_eliminar'][0]!= "no":
            cols_eliminar=args.preproceso['cols_eliminar']
            data = data.drop(cols_eliminar, axis=1)
        
        # Realizamos Oversampling o Undersampling
        over_under_sampling()
        print("Despues del preprocesado")  
        print(data.head())  # Esto imprimir√° las primeras 5 filas de todas las columnas por defecto
        

    return data

    
def concatenar_columnas(data, columnas):
    """
    Concatenar varias columnas en un nuevo columna llamada 'concatenada'.
    
    Par√°metros:
    - X_train: DataFrame de pandas que contiene las columnas a concatenar.
    - columnas: Lista de nombres de las columnas que deseas concatenar.
    - sep: Separador que se usar√° para concatenar las columnas (por defecto es ',').
    
    Retorna:
    - DataFrame con la columna 'concatenada' a√±adida.
    """
    sep=' '
    # Verificar que la lista de columnas tiene al menos dos columnas
    if len(columnas) < 2:
        raise ValueError("La lista de columnas debe contener al menos dos columnas.")
    
    # Asegurarse de que no haya valores NaN antes de concatenar
    for col in columnas:
        data[col] = data[col].fillna('')  # Reemplazar NaN por una cadena vac√≠a
    
    # Usar str.cat() para concatenar las columnas seleccionadas
    data[columnas[0]] = data[columnas[0]].str.cat(data[columnas[1]], sep=sep)
    
    # Si hay m√°s de dos columnas, concatenarlas
    for col in columnas[2:]:
        data[columnas[0]] = data[columnas[0]].str.cat(data[col], sep=sep)
    
    return data

def guardarModelo(clf):
    nombreModel = "nombreParAlmacenar.sav"
    with open(nombreModel, 'wb') as archivo:
        pickle.dump(clf, archivo)
    print("Modelo guardado correctamente empleando Pickle")

def cargarModelo(nombreModel):
    with open(nombreModel, 'rb') as archivo:
        modelo = pickle.load(archivo)
    return modelo
def remove_outliers_iqr(column):
    """
    Elimina los outliers utilizando el m√©todo del Rango Intercuart√≠lico (IQR).
    
    Par√°metros:
    - df: DataFrame, el conjunto de datos.
    - column: str, el nombre de la columna sobre la que se aplicar√° la detecci√≥n de outliers.
    
    Retorna:
    - df: DataFrame, el conjunto de datos sin los outliers.
    """
    global data
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    
    # Definimos el l√≠mite inferior y superior para los outliers
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    # Filtramos los valores fuera de este rango
    data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]
#Preprocesado      
def limpiar_texto(texto):
    """
    Limpia y normaliza texto basado en configuraciones de `miJson`:
    - Convierte a min√∫sculas
    - Elimina acentos y caracteres especiales
    - Elimina stopwords
    - Aplica lematizaci√≥n
    """

    # Obtener la configuraci√≥n de preprocesamiento
    opciones = miJson.get('preproceso', {}).get('normalize_vector', [])

    lemmatizer = WordNetLemmatizer()
    stop_words_list = set(stopwords.words("english")) if "stopwords" in opciones else set()

    # Si el texto es NaN, None o vac√≠o, devolverlo sin cambios
    if texto is None or texto == "" or pd.isna(texto):
        return texto

    # 1. Convertir a min√∫sculas
    if "minusculas" in opciones:
        texto = texto.lower().strip()

    # 2. Quitar acentos
    if "acentos" in opciones:
        texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')

    # 3. Eliminar caracteres especiales y n√∫meros
    if "caracEsp" in opciones:
        texto = re.sub(r'[^a-z\s]', '', texto)

    # 4. Tokenizar el texto (convertir en lista de palabras)
    palabras = word_tokenize(texto, language="english") if "tokenizar" in opciones else texto.split()

    # 5. Eliminar stopwords y aplicar lematizaci√≥n si est√° activado
    if "lematizar" in opciones:
        palabras = [lemmatizer.lemmatize(p) for p in palabras if p not in stop_words_list]

    # 6. Unir palabras procesadas en una sola cadena
    texto_limpio = " ".join(palabras)

    return texto_limpio

def cat_numerico(df, columnas):
    """
    Convierte columnas categ√≥ricas a num√©ricas usando pd.factorize().
    
    Par√°metros:
    - df: DataFrame de Pandas
    - columnas: Lista de nombres de columnas a convertir (opcional).
                Si es None, convierte todas las categ√≥ricas.

    Retorna:
    - DataFrame con las columnas convertidas a valores num√©ricos.
    """
    if columnas is None:
        # Si no se especifican columnas, convertir todas las categ√≥ricas
        columnas = df.select_dtypes(exclude=['number']).columns.tolist()
    else:
        # Filtrar solo las que existen en el DataFrame
        columnas = [col for col in columnas if col in df.columns]

    # Aplicar pd.factorize() a las columnas seleccionadas
    df[columnas] = df[columnas].apply(lambda x: pd.factorize(x)[0])
    
    return df

###############ESCALADO############
def z_score(v):
    """Escala una columna usando el m√©todo Z-Score, asegurando que sea num√©rica."""
    
    # Imprime el tipo para depuraci√≥n
    print(f"Tipo de v: {type(v)}")

    # Si v es un solo valor string (no una columna), lo devolvemos sin cambios
    if isinstance(v, str):
        return v
    
    # Convertimos a Serie si es necesario
    if isinstance(v, (list, np.ndarray)):
        v = pd.Series(v)

    # Verificamos si es num√©rico
    if not np.issubdtype(v.dtype, np.number):  
        return v  # Retorna sin cambios si no es num√©rico

    return (v - v.mean()) / v.std()
def maximum_absolute_scaling(df):
    """Escala columnas num√©ricas con media > 60 usando el escalado m√°ximo absoluto."""
    df_scaled = df.copy()
    for column in df_scaled.select_dtypes(include=[np.number]).columns:  # Solo num√©ricas
        if df_scaled[column].mean() > 60:
            df_scaled[column] = df_scaled[column] / df_scaled[column].abs().max()
    return df_scaled
def min_max_scaling(v):
    """Escala una columna usando el m√©todo Min-Max."""
    # Convertir a NumPy array asegurando que sean n√∫meros
    try:
        v = np.array(v, dtype=float)  # Convierte a n√∫meros si es posible
    except ValueError:
        print("Error: La columna contiene valores no num√©ricos.", v)
        return None  # Evita procesar datos incorrectos
    print(type(v))
    if not np.issubdtype(v.dtype, np.number):
        return v  # Retorna sin cambios si es texto
    return (v - v.min()) / (v.max() - v.min())
    return v_norm 
def escaladoEstandar(df):
    """Escala todo el DataFrame usando StandardScaler de sklearn sin modificar el original."""
    df_scaled = df.copy()  # Copia el DataFrame para evitar modificaciones en el original
    num_cols = df_scaled.select_dtypes(include=[np.number]).columns  # Selecciona solo columnas num√©ricas
    sc = StandardScaler()
    
    # Guardamos los tipos originales
    dtypes_originales = df_scaled[num_cols].dtypes  
    
    # Escalamos las columnas num√©ricas
    df_scaled[num_cols] = sc.fit_transform(df_scaled[num_cols])
    
    # Restauramos el tipo de dato original para evitar problemas
    for col in num_cols:
        if np.issubdtype(dtypes_originales[col], np.integer):
            df_scaled[col] = df_scaled[col].astype(int)  # Convierte de vuelta a enteros
    
    return df_scaled
def process_text(text_feature):
    """
    Procesa las caracter√≠sticas de texto utilizando t√©cnicas de vectorizaci√≥n como TF-IDF o BOW.

    Par√°metros:
    text_feature (pandas.DataFrame): Un DataFrame que contiene las caracter√≠sticas de texto a procesar.

    """
    global data
    try:
        if text_feature.columns.size > 0:
            if args.preproceso["max_arg_textProcessor"]!="no":
                max_featuresPre=args.preproceso["max_arg_textProcessor"]
            else:
                max_featuresPre=None
            text_data = data[text_feature.columns].apply(lambda x: ' '.join(x.astype(str)), axis=1)
            if args.preproceso["text_process"] == "tf-idf":     
                if args.mode == "train":
                    tfidf_vectorizer = TfidfVectorizer(max_features=max_featuresPre)
                    tfidf_matrix = tfidf_vectorizer.fit_transform(text_data)
                    joblib.dump(tfidf_vectorizer, "tfidf_vectorizer.pkl")
                else:  # modo == "predict o test"
                    tfidf_vectorizer = joblib.load("tfidf_vectorizer.pkl")
                    tfidf_matrix = tfidf_vectorizer.transform(text_data)

                # ‚úÖ √çndice alineado para evitar NaNs ocultos
                text_features_df = pd.DataFrame(
                    tfidf_matrix.toarray(),
                    columns=tfidf_vectorizer.get_feature_names_out(),
                    index=data.index
                )

                data = pd.concat([data, text_features_df], axis=1)
                data.drop(text_feature.columns, axis=1, inplace=True)

                print(Fore.GREEN + "Texto tratado con √©xito usando TF-IDF" + Fore.RESET)

            elif args.preproceso["text_process"] == "bow":
                if args.mode == "train":
                    bow_vectorizer = CountVectorizer()
                    bow_matrix = bow_vectorizer.fit_transform(text_data)
                    joblib.dump(bow_vectorizer, "bow_vectorizer.pkl")
                else:
                    bow_vectorizer = joblib.load("bow_vectorizer.pkl")
                    bow_matrix = bow_vectorizer.transform(text_data)

                # Tambi√©n puede alinearse por si acaso
                text_features_df = pd.DataFrame(
                    bow_matrix.toarray(),
                    columns=bow_vecotirizer.get_feature_names_out(),
                    index=data.index
                )

                data = pd.concat([data, text_features_df], axis=1)
                print(Fore.GREEN + "Texto tratado con √©xito usando BOW" + Fore.RESET)

            else:
                print(Fore.YELLOW + "No se est√°n tratando los textos" + Fore.RESET)
        else:
            print(Fore.YELLOW + "No se han encontrado columnas de texto a procesar" + Fore.RESET)
    except Exception as e:
        print(Fore.RED+"Error al tratar el texto"+Fore.RESET)
        print(e)
        sys.exit(1)

def over_under_sampling():
    """
    Realiza oversampling o undersampling en los datos seg√∫n la estrategia especificada en args.preproceso["sampling"].
    
    Args:
        None
    
    Returns:
        None
    
    Raises:
        Exception: Si ocurre alg√∫n error al realizar el oversampling o undersampling.
    """
    
    global data
    if args.mode == "train":
        try:
            if args.preproceso["sampling"] == "oversampling":
                ros = RandomOverSampler(sampling_strategy='minority', random_state=42)
                x = data.drop(columns=[args.prediction])
                y = data[args.prediction]
                x, y = ros.fit_resample(x, y)
                x = pd.DataFrame(x, columns=data.drop(columns=[args.prediction]).columns)
                y = pd.Series(y, name=args.prediction)
                data = pd.concat([x, y], axis=1)
                print(Fore.GREEN+"Oversampling realizado con √©xito"+Fore.RESET)
            elif args.preproceso["sampling"] == "undersampling":
                rus = RandomUnderSampler(sampling_strategy='majority', random_state=42)
                x = data.drop(columns=[args.prediction])
                y = data[args.prediction]
                x, y = rus.fit_resample(x, y)
                x = pd.DataFrame(x, columns=data.drop(columns=[args.prediction]).columns)
                y = pd.Series(y, name=args.prediction)
                data = pd.concat([x, y], axis=1)
                print(Fore.GREEN+"Undersampling realizado con √©xito"+Fore.RESET)
            elif args.preproceso["sampling"] == "SMOTE":
                x = data.drop(columns=[args.prediction])
                y = data[args.prediction]
                x,y=SMOTE().fit_resample(x,y)
                x = pd.DataFrame(x, columns=data.drop(columns=[args.prediction]).columns)
                y = pd.Series(y, name=args.prediction)
                data = pd.concat([x, y], axis=1)
            elif args.preproceso["sampling"] == "ADASYN":
                x = data.drop(columns=[args.prediction])
                y = data[args.prediction]
                x,y=ADASYN().fit_resample(x,y)
                x = pd.DataFrame(x, columns=data.drop(columns=[args.prediction]).columns)
                y = pd.Series(y, name=args.prediction)
                data = pd.concat([x, y], axis=1)

            else:
                print(Fore.YELLOW+"No se est√°n realizando oversampling o undersampling"+Fore.RESET)
        except Exception as e:
            print(Fore.RED+"Error al realizar oversampling o undersampling"+Fore.RESET)
            print(e)
            sys.exit(1)
    else:
        print(Fore.GREEN+"No se realiza oversampling o undersampling en modo test"+Fore.RESET)

def drop_features():
    """
    Elimina las columnas especificadas del conjunto de datos.

    Par√°metros:
    features (list): Lista de nombres de columnas a eliminar.

    """
    global data
    try:
        data = data.drop(columns=args.preprocessing["drop_features"])
        print(Fore.GREEN+"Columnas eliminadas con √©xito"+Fore.RESET)
    except Exception as e:
        print(Fore.RED+"Error al eliminar columnas"+Fore.RESET)
        print(e)
        sys.exit(1)



# Funciones para entrenar un modelo

def divide_data():
    """
    Funci√≥n que divide los datos en conjuntos de entrenamiento y desarrollo.

    Par√°metros:
    - data: DataFrame que contiene los datos.
    - args: Objeto que contiene los argumentos necesarios para la divisi√≥n de datos.

    Retorna:
    - x_train: DataFrame con las caracter√≠sticas de entrenamiento.
    - x_dev: DataFrame con las caracter√≠sticas de desarrollo para evaluar el entrenamiento.
    - y_train: Serie con las etiquetas de entrenamiento.
    - y_dev: Serie con las etiquetas de desarrollo para evaluar el entrenamiento.
    - x_dev: DataFrame con las caracter√≠sticas de desarrollo para evaluar un modelo entrenado.
    - y_dev: Serie con las etiquetas de desarrollo para evaluar un modelo entrenado.
    """
    global data
    # Nombre de la columna que quieres mover
    columna_target = args.prediction
    # Reorganizar el DataFrame para mover el target al final
    data = data[[col for col in data.columns if col != columna_target] + [columna_target]]
    #  Seleccionamos las caracter√≠sticas y la clase
    x= data.iloc[:, :-1].values # Todas las columnas menos la √∫ltima
    y = data.iloc[:, -1].values # √öltima columna
    
    # Dividimos los datos en entrenamiento y dev
    x_train, x_dev, y_train, y_dev = train_test_split(x, y, test_size=0.25, random_state=42)
    x_dev,x_devTest, y_dev,y_devTest = train_test_split(x_dev, y_dev, test_size=0.5, random_state=42)
    print(f"Shape de X_train: {x_train.shape}")
    print(f"Shape de X_dev: {x_dev.shape}")
    print(f"Shape de X_devTest: {x_devTest.shape}")

    info_y("y_train", y_train)
    info_y("y_dev", y_dev)
    info_y("y_devTest", y_devTest)

    if args.mode=='train' :
        return x_train, x_dev, y_train, y_dev
    elif args.mode == "test":
        return x_devTest,y_devTest
# Informaci√≥n de las Y
def info_y(nombre, y_array):
    valores_unicos, conteos = np.unique(y_array, return_counts=True)
    print(f"\n[{nombre}]")
    print(f"N√∫mero de valores distintos: {len(valores_unicos)}")
    print(f"Tipos de datos: {[type(val) for val in valores_unicos]}")
    print("Valores √∫nicos y sus cantidades:")
    for valor, conteo in zip(valores_unicos, conteos):
        print(f"  Valor {valor}: {conteo} ejemplos")


def save_model(gs):
    """
    Guarda el modelo y los resultados de la b√∫squeda de hiperpar√°metros en archivos.

    Par√°metros:
    - gs: objeto GridSearchCV, el cual contiene el modelo y los resultados de la b√∫squeda de hiperpar√°metros.

    Excepciones:
    - Exception: Si ocurre alg√∫n error al guardar el modelo.
    """
    try:
        with open('output/modelo.pkl', 'wb') as file:
            pickle.dump(gs, file)
            print(Fore.CYAN + "Modelo guardado con √©xito" + Fore.RESET)

        # Verificar si las m√©tricas existen en los resultados
        mean_f1 = gs.cv_results_.get('mean_test_f1_score', [None] * len(gs.cv_results_['params']))
        mean_accuracy = gs.cv_results_.get('mean_test_accuracy', [None] * len(gs.cv_results_['params']))
        mean_custom = gs.cv_results_.get(f'mean_test_custom', [None] * len(gs.cv_results_['params']))
        mean_recall= gs.cv_results_.get(f'mean_test_recall', [None] * len(gs.cv_results_['params']))
        mean_precision= gs.cv_results_.get(f'mean_test_precision', [None] * len(gs.cv_results_['params']))

        # Obtener y ordenar resultados si existen las m√©tricas
        results = sorted(
            zip(gs.cv_results_['params'], mean_custom, mean_f1, mean_accuracy,mean_recall,mean_precision),
            key=lambda x: x[1] if x[1] is not None else -1, reverse=True
        )

        # Guardar en CSV
        with open('output/modelo.csv', 'w', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(['Params', args.estimator, 'F1_Score', 'Accuracy','Recall','Precision'])
            writer.writerows(results)  # Escribir filas ordenadas

        print(Fore.GREEN + "Resultados guardados en CSV ordenados de mayor a menor" + Fore.RESET)

    except Exception as e:
        print(Fore.RED + "Error al guardar el modelo" + Fore.RESET)
        print(e)

def mostrar_resultados(gs, x_dev, y_dev):
    """
    Muestra los resultados del clasificador.

    Par√°metros:
    - gs: objeto GridSearchCV, el clasificador con la b√∫squeda de hiperpar√°metros.
    - x_dev: array-like, las caracter√≠sticas del conjunto de desarrollo.
    - y_dev: array-like, las etiquetas del conjunto de desarrollo.

    Imprime en la consola los siguientes resultados:
    - Mejores par√°metros encontrados por la b√∫squeda de hiperpar√°metros.
    - Mejor puntuaci√≥n obtenida por el clasificador.
    - F1-score micro del clasificador en el conjunto de desarrollo.
    - F1-score macro del clasificador en el conjunto de desarrollo.
    - Informe de clasificaci√≥n del clasificador en el conjunto de desarrollo.
    - Matriz de confusi√≥n del clasificador en el conjunto de desarrollo.
    """
    if args.verbose:
        print(Fore.MAGENTA+"> Mejores parametros:\n"+Fore.RESET, gs.best_params_)
        print(Fore.MAGENTA+"> Mejor puntuacion:\n"+Fore.RESET, gs.best_score_)
        print(Fore.MAGENTA+"> F1-score micro:\n"+Fore.RESET, calculate_fscore(y_dev, gs.predict(x_dev))[0])
        print(Fore.MAGENTA+"> F1-score macro:\n"+Fore.RESET, calculate_fscore(y_dev, gs.predict(x_dev))[1])
        print(Fore.MAGENTA+"> Informe de clasificaci√≥n:\n"+Fore.RESET, calculate_classification_report(y_dev, gs.predict(x_dev)))
        print(Fore.MAGENTA+"> Matriz de confusi√≥n:\n"+Fore.RESET, calculate_confusion_matrix(y_dev, gs.predict(x_dev)))

def kNN():
    """
    Funci√≥n para implementar el algoritmo kNN.
    Hace un barrido de hiperpar√°metros para encontrar los par√°metros √≥ptimos.

    :return: Tupla con la clasificaci√≥n de los datos.
    :rtype: tuple
    """
    global data

    # Dividimos los datos en entrenamiento y validaci√≥n
    x_train, x_dev, y_train, y_dev = divide_data()
    
    # Definimos los criterios de evaluaci√≥n
    scoring = {
        'custom': args.estimator,
        'f1_score': 'f1_weighted',
        'accuracy': 'accuracy',
        'recall':'recall_weighted',
        'Precision':'precision_weighted'
        

    }
    
    with tqdm(total=100, desc='Procesando kNN', unit='iter', leave=True) as pbar:
        gs = GridSearchCV(KNeighborsClassifier(), args.kNN, cv=5, n_jobs=args.cpu, scoring=scoring, refit='custom')
        start_time = time.time()
        gs.fit(x_train, y_train)
        end_time = time.time()
        
        for i in range(100):
            time.sleep(random.uniform(0.06, 0.15))  
            pbar.update(random.random() * 2)  
        pbar.n = 100
        pbar.last_print_n = 100
        pbar.update(0)
    
    execution_time = end_time - start_time
    print("Tiempo de ejecuci√≥n:" + Fore.MAGENTA, execution_time, Fore.RESET + " segundos")
    
    # Mostramos los resultados
    mostrar_resultados(gs, x_dev, y_dev)
    
    # Guardamos el modelo utilizando pickle
    save_model(gs)

def decision_tree():
    """
    Funci√≥n para implementar el algoritmo de √°rbol de decisi√≥n.

    :param data: Conjunto de datos para realizar la clasificaci√≥n.
    :type data: pandas.DataFrame
    :return: Tupla con la clasificaci√≥n de los datos.
    :rtype: tuple
    """
    # Dividimos los datos en entrenamiento y dev
    x_train, x_dev, y_train, y_dev = divide_data()
    
    # Definimos los criterios de evaluaci√≥n
    scoring = {
        'custom': args.estimator,
        'f1_score': 'f1_weighted',
        'accuracy': 'accuracy',
        'recall':'recall_weighted',
        'precision':'precision_weighted'
    }

    # Hacemos un barrido de hiperparametros
    with tqdm(total=100, desc='Procesando decision tree', unit='iter', leave=True) as pbar:
        gs = GridSearchCV(DecisionTreeClassifier(), args.decision_tree, cv=5, n_jobs=args.cpu, scoring=scoring, refit='custom')
        start_time = time.time()
        gs.fit(x_train, y_train)
        end_time = time.time()
        for i in range(100):
            time.sleep(random.uniform(0.06, 0.15))  # Esperamos un tiempo aleatorio
            pbar.update(random.random()*2)  # Actualizamos la barra con un valor aleatorio
        pbar.n = 100
        pbar.last_print_n = 100
        pbar.update(0)
    execution_time = end_time - start_time
    print("Tiempo de ejecuci√≥n:"+Fore.MAGENTA, execution_time,Fore.RESET+ "segundos")
    
    # Mostramos los resultados
    mostrar_resultados(gs, x_dev, y_dev)
    
    # Guardamos el modelo utilizando pickle
    save_model(gs)
    
def random_forest():
    """
    Funci√≥n que entrena un modelo de Random Forest utilizando GridSearchCV para encontrar los mejores hiperpar√°metros.
    Divide los datos en entrenamiento y desarrollo, realiza la b√∫squeda de hiperpar√°metros, guarda el modelo entrenado
    utilizando pickle y muestra los resultados utilizando los datos de desarrollo.

    Par√°metros:
        Ninguno

    Retorna:
        Ninguno
    """
    
    # Dividimos los datos en entrenamiento y dev
    x_train, x_dev, y_train, y_dev = divide_data()

    # Definimos los criterios de evaluaci√≥n
    scoring = {
        'custom': args.estimator,
        'f1_score': 'f1_weighted',
        'accuracy': 'accuracy',
        'recall':'recall_weighted',
        'precision':'precision_weighted'
    }
    
    # Hacemos un barrido de hiperparametros
    with tqdm(total=100, desc='Procesando random forest', unit='iter', leave=True) as pbar:
        gs = GridSearchCV(RandomForestClassifier(), args.random_forest, cv=5, n_jobs=args.cpu, scoring=scoring, refit='custom')
        start_time = time.time()
        gs.fit(x_train, y_train)
        end_time = time.time()
        for i in range(100):
            time.sleep(random.uniform(0.06, 0.15))  # Esperamos un tiempo aleatorio
            pbar.update(random.random()*2)  # Actualizamos la barra con un valor aleatorio
        pbar.n = 100
        pbar.last_print_n = 100
        pbar.update(0)
    execution_time = end_time - start_time
    print("Tiempo de ejecuci√≥n:"+Fore.MAGENTA, execution_time,Fore.RESET+ "segundos")
    
    # Mostramos los resultados
    mostrar_resultados(gs, x_dev, y_dev)
    
    # Guardamos el modelo utilizando pickle
    save_model(gs)
def naive_bayes():

    # Dividimos los datos en entrenamiento y dev
    x_train, x_dev, y_train, y_dev = divide_data()

    # Definimos los criterios de evaluaci√≥n
    scoring = {
        'custom': args.estimator,
        'f1_score': 'f1_weighted',
        'accuracy': 'accuracy',
        'recall':'recall_weighted',
        'precision':'precision_weighted'
    }

    # Hacemos un barrido de hiperparametros
    with tqdm(total=100, desc='Procesando naive bayes', unit='iter', leave=True) as pbar:
        gs = GridSearchCV(MultinomialNB(), args.naive_bayes, cv=5, n_jobs=args.cpu, scoring=scoring,refit='custom')
        start_time = time.time()
        gs.fit(x_train, y_train)
        end_time = time.time()
        for i in range(100):
            time.sleep(random.uniform(0.06, 0.15)) 
            pbar.update(random.random()*2)  
        pbar.n = 100
        pbar.last_print_n = 100
        pbar.update(0)
    execution_time = end_time - start_time
    print("Tiempo de ejecuci√≥n:"+Fore.MAGENTA, execution_time,Fore.RESET+ "segundos")
    
    # Mostramos los resultados
    mostrar_resultados(gs, x_dev, y_dev)
    
    # Guardamos el modelo utilizando pickle
    save_model(gs)

# Funciones para predecir con un modelo

def load_model():
    """
    Carga el modelo desde el archivo 'output/modelo.pkl' y lo devuelve.

    Returns:
        model: El modelo cargado desde el archivo 'output/modelo.pkl'.

    Raises:
        Exception: Si ocurre un error al cargar el modelo.
    """
    try:
        with open('output/modelo.pkl', 'rb') as file:
            model = pickle.load(file)
            print(Fore.GREEN+"Modelo cargado con √©xito"+Fore.RESET)
            return model
    except Exception as e:
        print(Fore.RED+"Error al cargar el modelo"+Fore.RESET)
        print(e)
        sys.exit(1)
        
def predict():
    """
    Realiza una predicci√≥n utilizando el modelo entrenado y guarda los resultados en un archivo CSV.

    Par√°metros:
        Ninguno

    Retorna:
        los datos con la prediccion
    """
    global data
   # Seleccionamos las caracter√≠sticas (todas las columnas menos la de predicci√≥n)(si la hay)
    x_data = data.drop(columns=[args.prediction], errors='ignore')

    # Predecimos
    prediction = model.predict(x_data)
    
    prediction_column_name = args.prediction + "Prediccion"
    data1 = load_data(args.file)
    data1 = pd.concat([data1, pd.DataFrame(prediction, columns=[prediction_column_name])], axis=1)
    return data1
def predictTest(X_devTest):
    """
    Realiza una predicci√≥n utilizando el modelo entrenado y guarda los resultados en un archivo CSV.

    Par√°metros:
        X_devTest:Datos para evaluar sin el targert
    Retorna:
        X_devTest:Datos evaaluados con el targert
    """
    global data
    if not isinstance(X_devTest, pd.DataFrame):
        X_devTest = pd.DataFrame(X_devTest, columns=data.columns[:-1])



    # Predecimos
    prediction = model.predict(X_devTest)
    
    prediction_column_name = args.prediction + "Prediccion"

    print(X_devTest.columns)  # Asegura que X_devTest tenga nombres de columnas

    X_devTest = pd.concat([X_devTest, pd.DataFrame(prediction, columns=[prediction_column_name])], axis=1)

    return X_devTest



    
# Funci√≥n principal

if __name__ == "__main__":
    #Cargo el JSON
    with open('config.json', 'r', encoding='utf-8') as file:
        miJson = json.load(file)  
    # Fijamos la semilla
    np.random.seed(42)
    print("=== Clasificador ===")
    # Manejamos la se√±al SIGINT (Ctrl+C)
    signal.signal(signal.SIGINT, signal_handler)
    # Parseamos los argumentos
    args = parse_args()
    # Si la carpeta output no existe la creamos
    print("\n- Creando carpeta output...")
    try:
        os.makedirs('output')
        print(Fore.GREEN+"Carpeta output creada con √©xito"+Fore.RESET)
    except FileExistsError:
        print(Fore.GREEN+"La carpeta output ya existe"+Fore.RESET)
    except Exception as e:
        print(Fore.RED+"Error al crear la carpeta output"+Fore.RESET)
        print(e)
        sys.exit(1)
    # Cargamos los datos
    print("\n- Cargando datos...")
    data = load_data(args.file)
    # Descargamos los recursos necesarios de nltk
    print("\n- Descargando diccionarios...")
    nltk.download('stopwords')
    nltk.download('punkt')
    nltk.download('wordnet')
    # Preprocesamos los datos
    print("\n- Preprocesando datos...")
    preproceso()
    if args.debug:
        try:
            print("\n- Guardando datos preprocesados...")
            data.to_csv('output/data-processed.csv', index=False)
            print(Fore.GREEN+"Datos preprocesados guardados con √©xito"+Fore.RESET)
        except Exception as e:
            print(Fore.RED+"Error al guardar los datos preprocesados"+Fore.RESET)
    if args.mode == "train":
        # Ejecutamos el algoritmo seleccionado
        print("\n- Ejecutando algoritmo...")
        if args.algorithm == "kNN":
            try:
                kNN()
                print(Fore.GREEN+"Algoritmo kNN ejecutado con √©xito"+Fore.RESET)
                sys.exit(0)
            except Exception as e:
                print(e)
        elif args.algorithm == "decision_tree":
            try:
                decision_tree()
                print(Fore.GREEN+"Algoritmo √°rbol de decisi√≥n ejecutado con √©xito"+Fore.RESET)
                sys.exit(0)
            except Exception as e:
                print(e)
        elif args.algorithm == "random_forest":
            try:
                random_forest()
                print(Fore.GREEN+"Algoritmo random forest ejecutado con √©xito"+Fore.RESET)
                sys.exit(0)
            except Exception as e:
                print(e)
        elif args.algorithm == "naive_bayes":
            try:
                naive_bayes()
                print(Fore.GREEN+"Algoritmo naive bayes ejecutado con √©xito"+Fore.RESET)
                sys.exit(0)
            except Exception as e:
                print(e)      
        else:
            print(Fore.RED+"Algoritmo no soportado"+Fore.RESET)
            sys.exit(1)
    elif args.mode == "test":
        # Cargamos el modelo
        print("\n- Cargando modelo...")
        model = load_model()
        # Predecimos
        print("\n- Prediciendo...")
        try:
            x_devTest,y_devTest=divide_data()
            X_devTestPred=predictTest(x_devTest)
            print(Fore.GREEN+"Predicci√≥n realizada con √©xito"+Fore.RESET)
            # Guardamos el dataframe con la prediccion
            #data.to_csv('output/data-prediction.csv', index=False)
            y_pred=X_devTestPred[args.prediction + "Prediccion"]
            dataf=pd.concat([X_devTestPred, pd.DataFrame(y_devTest, columns=["Target"])], axis=1)
            calcular_metricas_y_guardar(y_devTest, y_pred, dataf)
            
            # Calcula las m√©tricas
            print(Fore.MAGENTA + "> F1-score micro:\n" + Fore.RESET, calculate_fscore(y_devTest, y_pred))
            print(Fore.MAGENTA + "> F1-score macro:\n" + Fore.RESET, calculate_fscore(y_devTest, y_pred))
            print(Fore.MAGENTA + "> Informe de clasificaci√≥n:\n" + Fore.RESET, calculate_classification_report(y_devTest, y_pred))
            print(Fore.MAGENTA + "> Matriz de confusi√≥n:\n" + Fore.RESET, calculate_confusion_matrix(y_devTest, y_pred))

            print(Fore.GREEN + "Predicci√≥n guardada con √©xito" + Fore.RESET)
            sys.exit(0)
        except Exception as e:
            print("adios")
            print(e)
            sys.exit(1)
    elif args.mode == "prediction":
        # Cargamos el modelo
        print("\n- Cargando modelo...")
        model = load_model()
        # Predecimos
        print("\n- Prediciendo...")
        try:
            data1=predict()
            print(Fore.GREEN+"Predicci√≥n realizada con √©xito"+Fore.RESET)
            data1.to_csv('output/Prediction.csv', index=False)
        except Exception as e:
            print("adios")
            print(e)
            sys.exit(1)
    else:
        print(Fore.RED+"Modo no soportado"+Fore.RESET)
        sys.exit(1)
